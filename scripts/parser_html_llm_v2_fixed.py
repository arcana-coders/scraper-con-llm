# scripts/parser_html_llm_v2.py

import json
import csv
from datetime import datetime
from openai import OpenAI
from pathlib import Path
import re

# === CONFIGURACI√ìN ===
# Activa el modo de depuraci√≥n para ver todo en consola
MODO_DEPURACION = True

LLM = "llama3.1:8b"
client = OpenAI(base_url="http://localhost:11434/v1", api_key="ollama")

BASE_DIR = Path(__file__).resolve().parent.parent
HTML_DIR = BASE_DIR / "html"
CSV_DIR = BASE_DIR / "csv"
OUTPUT_JSON_CONSOLIDADO = CSV_DIR / "pedidos_consolidados.json"
OUTPUT_CSV_CONSOLIDADO = CSV_DIR / "pedidos_consolidados.csv"

# === PROMPTS PARA LA CADENA DE DOS PASOS ===

PROMPT_LIMPIEZA = """
Tu tarea es SOLAMENTE extraer y devolver el c√≥digo HTML de la tabla que contiene los pedidos de Amazon Seller Central.

INSTRUCCIONES IMPORTANTES:
1. Busca en el HTML una tabla que contenga m√∫ltiples filas con datos de pedidos (ID de pedido, fechas, productos, ASIN, SKU, etc.)
2. Extrae √öNICAMENTE esa tabla completa con sus tags <table>, <tr>, <td>, etc.
3. NO agregues explicaciones, comentarios ni texto adicional
4. NO digas "Aqu√≠ est√° el HTML" o similar
5. Devuelve SOLAMENTE el c√≥digo HTML de la tabla, nada m√°s

Si no encuentras una tabla clara, busca un div o contenedor que liste m√∫ltiples pedidos y devuelve ese HTML.

RESPONDE √öNICAMENTE CON HTML V√ÅLIDO.
"""

PROMPT_EXTRACCION = """
Eres un experto en extracci√≥n de datos. El siguiente c√≥digo HTML contiene una lista de pedidos de Amazon. Tu tarea es parsear este HTML y extraer la informaci√≥n de CADA pedido.

Devuelve una lista de objetos JSON, donde cada objeto representa un pedido. La estructura debe ser:

[
  {
    "fecha_pedido": "YYYY-MM-DD",
    "id_pedido": "000-0000000-0000000",
    "producto": "Nombre completo del producto",
    "asin": "B0XXXXXXXX",
    "sku": "SKU-DEL-PRODUCTO",
    "cantidad": 1,
    "subtotal": 1234.56,
    "estado_pedido": "No enviado"
  }
]

Reglas:
- Extrae la informaci√≥n para TODOS los pedidos que encuentres en el HTML.
- Convierte las fechas a formato ISO (YYYY-MM-DD).
- Limpia los valores num√©ricos, eliminando s√≠mbolos de moneda y usando un punto como separador decimal.
- Si un campo no se encuentra para un pedido, usa `null`.
- Tu respuesta debe ser √öNICAMENTE la lista de objetos JSON. No incluyas explicaciones, texto introductorio ni la palabra "json" al principio.
"""

def encontrar_html_mas_reciente(directorio: Path) -> Path | None:
    print(f"üîé Buscando archivos HTML en: {directorio}")
    archivos_html = list(directorio.glob("pedidos_*.html"))
    if not archivos_html:
        return None
    archivo_mas_reciente = max(archivos_html, key=lambda p: p.name)
    print(f"üìÑ Se usar√° el archivo m√°s reciente: {archivo_mas_reciente.name}")
    return archivo_mas_reciente

def llm_limpiar_html(html_crudo: str) -> str | None:
    print("ü§ñ Paso 1: Pidiendo al LLM que a√≠sle el HTML de la tabla de pedidos...")
    try:
        response = client.chat.completions.create(
            model=LLM,
            messages=[
                {"role": "system", "content": PROMPT_LIMPIEZA.strip()},
                {"role": "user", "content": html_crudo}
            ],
            temperature=0,
        )
        html_limpio = response.choices[0].message.content.strip()
        
        # *** AGREGANDO LOGS DETALLADOS ***
        if MODO_DEPURACION:
            print("\n" + "="*20 + " RESPUESTA CRUDA DEL LLM (PASO 1) " + "="*20)
            print(f"Longitud de respuesta: {len(html_limpio)} caracteres")
            print(f"Contiene '<': {'<' in html_limpio}")
            print(f"Primeros 500 caracteres:")
            print(repr(html_limpio[:500]))
            print("="*68 + "\n")
        
        return html_limpio
    except Exception as e:
        print(f"‚ùå Error en el Paso 1 (Limpieza con LLM): {e}")
        return None

def llm_extraer_datos(html_limpio: str) -> list[dict] | None:
    print("ü§ñ Paso 2: Pidiendo al LLM que extraiga los datos estructurados del HTML limpio...")
    try:
        response = client.chat.completions.create(
            model=LLM,
            messages=[
                {"role": "system", "content": PROMPT_EXTRACCION.strip()},
                {"role": "user", "content": html_limpio}
            ],
            response_format={"type": "json_object"},
            temperature=0,
        )
        content = response.choices[0].message.content.strip()
        
        if MODO_DEPURACION:
            print("\n" + "="*20 + " RESPUESTA CRUDA DEL LLM (PASO 2) " + "="*20)
            print(content)
            print("="*68 + "\n")

        parsed_json = json.loads(content)
        if isinstance(parsed_json, list):
            return parsed_json
        elif isinstance(parsed_json, dict):
             # Si el LLM devuelve un solo objeto en lugar de una lista, lo envolvemos en una lista para poder procesarlo
             print("‚ÑπÔ∏è  El LLM devolvi√≥ un solo objeto, se convertir√° en una lista de un solo elemento.")
             return [parsed_json]
        else:
            print(f"‚ö†Ô∏è La respuesta del LLM no es una lista ni un diccionario. Tipo: {type(parsed_json)}")
            return None

    except Exception as e:
        print(f"‚ùå Error en el Paso 2 (Extracci√≥n con LLM): {e}")
        return None

def guardar_datos(datos: list[dict]):
    if not datos:
        print("‚ÑπÔ∏è No hay datos para guardar.")
        return

    CSV_DIR.mkdir(parents=True, exist_ok=True)

    # Guardar JSON
    with open(OUTPUT_JSON_CONSOLIDADO, "w", encoding="utf-8") as f:
        json.dump(datos, f, indent=2, ensure_ascii=False)
    print(f"üíæ JSON guardado en: {OUTPUT_JSON_CONSOLIDADO}")

    # Guardar CSV
    if datos:
        keys = datos[0].keys()
        with open(OUTPUT_CSV_CONSOLIDADO, "w", newline="", encoding="utf-8") as f:
            writer = csv.DictWriter(f, fieldnames=keys)
            writer.writeheader()
            writer.writerows(datos)
        print(f"üíæ CSV guardado en: {OUTPUT_CSV_CONSOLIDADO}")

def main():
    if MODO_DEPURACION:
        print("="*50)
        print("üïµÔ∏è  SCRIPT EN MODO DEPURACI√ìN üïµÔ∏è")
        print("Se mostrar√° informaci√≥n detallada en consola.")
        print("="*50)

    html_path = encontrar_html_mas_reciente(HTML_DIR)
    if not html_path:
        print("‚ùå No se encontraron archivos 'pedidos_*.html'. Saliendo.")
        return

    print(f"üìñ Leyendo el contenido crudo de {html_path.name}...")
    html_crudo = html_path.read_text(encoding="utf-8")
    
    # *** AGREGANDO LOG DEL TAMA√ëO DEL ARCHIVO ***
    print(f"üìä Archivo HTML cargado: {len(html_crudo)} caracteres, {len(html_crudo.splitlines())} l√≠neas")

    # --- Inicia la Cadena de LLM ---
    html_limpio = llm_limpiar_html(html_crudo)
    
    if not html_limpio or "<" not in html_limpio:
        print("üõë El LLM no devolvi√≥ un fragmento de HTML v√°lido en el paso de limpieza. El proceso termina.")
        return
    
    print("‚úÖ Paso 1 completado. HTML de la tabla aislado.")

    if MODO_DEPURACION:
        print("\n" + "="*20 + " HTML AISLADO ENVIADO AL PASO 2 " + "="*20)
        print(html_limpio)
        print("="*66 + "\n")

    pedidos_del_html = llm_extraer_datos(html_limpio)
    
    if not pedidos_del_html:
        print("üõë El LLM no extrajo ning√∫n pedido del HTML limpio. El proceso termina.")
        return

    # Si estamos en modo depuraci√≥n, solo mostramos lo que se extrajo y terminamos.
    if MODO_DEPURACION:
        print("üì¶ Contenido extra√≠do por el LLM en modo depuraci√≥n:")
        print(json.dumps(pedidos_del_html, indent=2, ensure_ascii=False))
        print("\nüèÅ Proceso de depuraci√≥n completado. No se guard√≥ nada.")
        return

    print(f"‚úÖ Paso 2 completado. Se extrajeron {len(pedidos_del_html)} pedidos del HTML.\n")
    
    # --- L√≥gica de actualizaci√≥n (solo se ejecuta si MODO_DEPURACION es False) ---
    pedidos_existentes = []
    ids_existentes = set()
    if OUTPUT_JSON_CONSOLIDADO.exists():
        print(f"üìÇ Leyendo archivo JSON existente: {OUTPUT_JSON_CONSOLIDADO}")
        try:
            with open(OUTPUT_JSON_CONSOLIDADO, "r", encoding="utf-8") as f:
                contenido = f.read()
                if contenido:
                    pedidos_existentes = json.loads(contenido)
                    ids_existentes = {p.get("id_pedido") for p in pedidos_existentes if p.get("id_pedido")}
            print(f"üîç Encontrados {len(pedidos_existentes)} pedidos existentes.")
        except json.JSONDecodeError:
             print("‚ö†Ô∏è El archivo JSON existe pero est√° vac√≠o o corrupto.")
    else:
        print("üìã No se encontr√≥ un archivo JSON previo.")

    nuevos_pedidos = []
    for pedido_html in pedidos_del_html:
        id_actual = pedido_html.get("id_pedido")
        if id_actual and id_actual not in ids_existentes:
            print(f"‚ú® Pedido nuevo encontrado: {id_actual}. Se agregar√°.")
            pedido_html["fecha_procesado"] = datetime.now().isoformat()
            nuevos_pedidos.append(pedido_html)

    if not nuevos_pedidos:
        print("\nüèÅ No se encontraron pedidos nuevos para agregar. Los archivos est√°n actualizados.")
    else:
        print(f"\n‚ûï Se agregar√°n {len(nuevos_pedidos)} pedidos nuevos a los archivos.")
        lista_final = sorted(pedidos_existentes + nuevos_pedidos, key=lambda p: p.get("fecha_procesado", ""))
        
        CSV_DIR.mkdir(parents=True, exist_ok=True)
        guardar_datos(lista_final)

    print("\n‚úÖ Proceso completado.")

if __name__ == "__main__":
    main()
